{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "An overfitted model performs well on training data but fails to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How to overcome overfitting:\n",
    "    1.weight regularization\n",
    "    2.more data\n",
    "    3.drop out\n",
    "    4.dec network capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization\n",
    "      Regularization is a technique to discourage the complexity of the model. \n",
    "      It does this by penalizing the loss function. This helps to solve the overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADIENT DESCENT OPTIMIZER:\n",
    "    in each epoch no wise each records is passed and their weights r updated accoring to loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCASHTIC GRADIENT DESCENT OPTIMIZER:\n",
    "    Randomly record is picked and trained, (weights r adjusted)\n",
    "    but all records r passed not left any\n",
    "    slow, time consuiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI-BATCH GRADIENT DESCENT OPTIMIZER:\n",
    "    Some group of are passed through model in an epoch and thier weihgts r updated\n",
    "    batch size is defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 AND L2 REGULARIZATION:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP OUT:\n",
    "    for regularization\n",
    "    it doesnt means that records/rows r deletd but some of the features or columns are deleted and replaced as zero..\n",
    "    it is applied only on training data\n",
    "\n",
    "DISADVANATGE:\n",
    "    bad training accuracy but generalization gets better(better performance on unseen data)\n",
    "    may delete useful column, from which model could have extracted useful info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 regularization\n",
    "    L1 regularization is also referred as L1 norm or Lasso.\n",
    "    In L1 norm we shrink the parameters to zero.\n",
    "    When input features have weights closer to zero that leads to sparse L1 norm.\n",
    "    In Sparse solution majority of the input features have zero weights \n",
    "    and very few features have non zero weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 regularization does feature selection. \n",
    "It does this by assigning insignificant input features with zero weight and useful features with a non zero weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 Regularization\n",
    "    L2 regularization forces the weights to be small but does not\n",
    "    make them zero and does non sparse solution.\n",
    "    L2 is not robust to outliers as square terms blows up the error \n",
    "    differences of the outliers and the regularization term tries to fix it by penalizing the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE UNIVERSAL WORKFLOW OF MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Defining the problem and getting the data-set \n",
    "    explorotory analysis\n",
    "    1.what will be input data\n",
    "    2.what do u want to predict from it\n",
    "    3.what type of problem ur trying to face , like multi-class, binary class\n",
    "    4.which loss function to be used according to the given problem\n",
    "    5.choose a measue of success\n",
    "    6.activation function of last layer and loss function\n",
    "    7.Deciding an evaluation protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete:\n",
    "    apple,chair,1,2,door,ali\n",
    "    some fixed diff btwenn no like after 1 its 2\n",
    "continous:\n",
    "    the range betwenn 1 and 2\n",
    "    no of fractions between 1 and 2\n",
    "    floating point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON-STATIONARY PROBELMS:\n",
    "    like recommender system made in june,july and prediction made in dec do wrong approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BALANCED CLASSIFICATION:\n",
    "    Equal no ofrecords for each classand each one is equally likely to occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSING A MEASURE OF SUCCESS\n",
    "    ROC CURVE , AUC\n",
    "    true positive rate:\n",
    "    whcih one of canser patients are correctly labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".Deciding an evaluation protocol\n",
    "    hold out : large dataset\n",
    "    k-fold : small data set\n",
    "    iterated k fold validation : one parent loop , shuffling of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch:\n",
    "    one iteration per sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how to get better accuracy:\n",
    "    add more layers\n",
    "    make bigger layers(more nodes)\n",
    "    train for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters:\n",
    "    w and b\n",
    "    \n",
    "hyper-parameters:\n",
    "    configuration of model\n",
    "    last func activ fun, loss fun, activation fun, no of layers, no of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularizing the model:\n",
    "    add drop-outs\n",
    "    add layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
